{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb478b2c-4230-4989-a332-9ee9ac3137b7",
   "metadata": {},
   "source": [
    "### Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cee11a6e-7566-40d7-811c-e0146b73c5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-25 23:29:23.217886: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1735162163.239008    4921 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1735162163.245519    4921 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-25 23:29:23.267466: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b80c7f4-3cb6-4459-867f-9fa4b5b48834",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f8d91-12e3-48d9-9831-38e7a55c7bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = 43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb7a5eb-f959-47fa-b6fc-0c927b3ccd59",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4476809c-dcf4-4ed7-8be9-73f7f2c55038",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape=(32, 32, 3), learning_rate=0.0001):\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "\n",
    "        # Convolutional layer 1\n",
    "        layers.Conv2D(32, (3,3), activation='relu', input_shape=input_shape),\n",
    "\n",
    "        # Pooling layer 1\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "\n",
    "        # Convolutional layer 2\n",
    "        layers.Conv2D(64, (3,3), activation='relu', input_shape=input_shape),\n",
    "        \n",
    "        # Pooling layer 2\n",
    "        layers.MaxPooling2D((2,2)),\n",
    "        \n",
    "        # Convolutional layer 3\n",
    "        layers.Conv2D(128, (3,3), activation='relu', input_shape=input_shape),\n",
    "        \n",
    "        # Flatten layer\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Dense layer 1\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        \n",
    "        # Dropout layer\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Dense layer 2\n",
    "        layers.Dense(43, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = keras.optimizers.Adam(learning_rate)\n",
    "    \n",
    "    # Loss\n",
    "    loss = keras.losses.CategoricalCrossentropy()\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=optimizer, \n",
    "                  loss=loss,\n",
    "                  metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245eb9a5-0017-43b3-b46a-a248d5e62fb7",
   "metadata": {},
   "source": [
    "### Resize all images to 32x32 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "822c55f7-a113-4fa7-8dbc-f2c930beca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_images(size=(32, 32)):\n",
    "    for i in range(classes):\n",
    "        input_directory = f\"../app/data/train/{i}\"\n",
    "        output_directory = f\"../app/data/train-r/{i}\"\n",
    "        \n",
    "        if not os.path.exists(output_directory):\n",
    "            os.makedirs(output_directory)\n",
    "    \n",
    "        for filename in os.listdir(input_directory):\n",
    "            input_path = os.path.join(input_directory, filename)\n",
    "            output_path = os.path.join(output_directory, filename)\n",
    "    \n",
    "            try:\n",
    "                with Image.open(input_path) as img:\n",
    "                    img = img.resize(size)\n",
    "                    img.save(output_path)\n",
    "                    print(f\"Resized and saved: {output_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_path}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c136952-7e8a-4ae8-8289-13f9786b76eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_images(size=(32, 32))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de64174-6604-4120-b5e6-879d22574e94",
   "metadata": {},
   "source": [
    "### Load train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "663e9330-b3a3-4551-8413-e6671689c954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    \n",
    "    sign_images = []\n",
    "    sign_indexes = []\n",
    "\n",
    "    for i in range(classes):\n",
    "        \n",
    "        input_directory = f\"../app/data/train-r/{i}\"\n",
    "        \n",
    "        for filename in os.listdir(input_directory):\n",
    "            input_path = os.path.join(input_directory, filename)\n",
    "\n",
    "            try:\n",
    "                with Image.open(input_path) as img:\n",
    "                    sign_images.append(np.array(img))\n",
    "                    sign_indexes.append(i)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {input_path}: {e}\")\n",
    "\n",
    "    sign_images = np.array(sign_images)\n",
    "    sign_indexes = np.array(sign_indexes)\n",
    "\n",
    "    return sign_images, sign_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7afdcbd-68ef-46cd-a90f-28cb76830f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sign_images, sign_indexes = load_images()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316962e-e60b-412b-8c3d-afea8889cea9",
   "metadata": {},
   "source": [
    "### Split train images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c8f8027-ffaa-427e-95c8-ec673b581315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test folder already exists so we split the sign images into train and validation\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(sign_images, sign_indexes, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "710a768a-5270-41f8-ad7b-15ae16e5aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1d1fa0ae-350f-44c4-b6c8-40bd52805a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((39209, 32, 32, 3), (39209,))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sign_images.shape, sign_indexes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c37e2a1-2906-4376-ae12-cd369229c8af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31367, 32, 32, 3), (7842, 32, 32, 3))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6463f11b-d295-43b0-b8c1-bf4bcd6d7a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31367, 43), (7842, 43))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b661906-54d3-4f69-832d-7a3b6447283a",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7846e59f-ed3b-4f08-8def-03bda6984bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape=(32, 32, 3), learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf69fa6e-f41b-4b4b-9b78-446bc806cfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72b7c1-fe80-4bd4-a00b-baad56450089",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = keras.callbacks.ModelCheckpoint (\n",
    "    \"traffic_sign_classification_model.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_accuracy\"\n",
    ")\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    validation_data=(X_val, y_val), \n",
    "                    epochs=35,\n",
    "                    batch_size=32,\n",
    "                    callbacks=[checkpoint]\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a0d64f-e210-4033-8315-2ef6d2ab3879",
   "metadata": {},
   "source": [
    "### Plot accuracy and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0f079e-053a-408b-a463-1422b2e2a589",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train')\n",
    "plt.plot(history.history['val_accuracy'], label='val')\n",
    "plt.plot(history.history['loss'], label='loss')\n",
    "plt.plot(history.history['val_loss'], label='val_loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebd67f1-7b16-435a-88cb-74d97a6698d6",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78105b8-d79f-460f-acc3-e9f6552c1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_descriptions = {\n",
    "    0: 'Speed limit (20km/h)',\n",
    "    1: 'Speed limit (30km/h)',\n",
    "    2: 'Speed limit (50km/h)',\n",
    "    3: 'Speed limit (60km/h)',\n",
    "    4: 'Speed limit (70km/h)',\n",
    "    5: 'Speed limit (80km/h)',\n",
    "    6: 'End of speed limit (80km/h)',\n",
    "    7: 'Speed limit (100km/h)',\n",
    "    8: 'Speed limit (120km/h)',\n",
    "    9: 'No passing',\n",
    "    10: 'No passing for vehicles over 3.5 metric tons',\n",
    "    11: 'Right-of-way at the next intersection',\n",
    "    12: 'Priority road',\n",
    "    13: 'Yield',\n",
    "    14: 'Stop',\n",
    "    15: 'No vehicles',\n",
    "    16: 'Vehicles over 3.5 metric tons prohibited',\n",
    "    17: 'No entry',\n",
    "    18: 'General caution',\n",
    "    19: 'Dangerous curve to the left',\n",
    "    20: 'Dangerous curve to the right',\n",
    "    21: 'Double curve',\n",
    "    22: 'Bumpy road',\n",
    "    23: 'Slippery road',\n",
    "    24: 'Road narrows on the right',\n",
    "    25: 'Road work',\n",
    "    26: 'Traffic signals',\n",
    "    27: 'Pedestrians',\n",
    "    28: 'Children crossing',\n",
    "    29: 'Bicycles crossing',\n",
    "    30: 'Beware of ice/snow',\n",
    "    31: 'Wild animals crossing',\n",
    "    32: 'End of all speed and passing limits',\n",
    "    33: 'Turn right ahead',\n",
    "    34: 'Turn left ahead',\n",
    "    35: 'Ahead only',\n",
    "    36: 'Go straight or right',\n",
    "    37: 'Go straight or left',\n",
    "    38: 'Keep right',\n",
    "    39: 'Keep left',\n",
    "    40: 'Roundabout mandatory',\n",
    "    41: 'End of no passing',\n",
    "    42: 'End of no passing by vehicles over 3.5 metric'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f52960ae-3f2a-49e1-938d-2bb1138ec19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function gets a traffic sign image as an input and makes a prediction\n",
    "def make_prediction(image):\n",
    "    # Load model\n",
    "    model = keras.models.load_model('./app/model/traffic_sign_classification_model.h5')\n",
    "    \n",
    "    # Load image\n",
    "    img = load_img(image, target_size=(32,32))\n",
    "\n",
    "    # Create image matrix\n",
    "    x = np.array(img)\n",
    "    X = np.array([x])\n",
    "    print(type(x))\n",
    "    print(X.shape)\n",
    "    \n",
    "    # Make prediction\n",
    "    pred = model.predict(X)\n",
    "\n",
    "    # Get class info\n",
    "    class_index = pred[0].argmax()\n",
    "    class_name = class_descriptions[class_index]\n",
    "\n",
    "    # Return info\n",
    "    return class_index, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a17b47c-932f-432a-8986-539860541903",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = '../app/data/test/00000.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0e90b97-ac3a-4d96-b05b-a288f2784d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(1, 32, 32, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 431ms/step\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'class_descriptions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m class_index, class_name \u001b[38;5;241m=\u001b[39m \u001b[43mmake_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[11], line 20\u001b[0m, in \u001b[0;36mmake_prediction\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Get class info\u001b[39;00m\n\u001b[1;32m     19\u001b[0m class_index \u001b[38;5;241m=\u001b[39m pred[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39margmax()\n\u001b[0;32m---> 20\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[43mclass_descriptions\u001b[49m[class_index]\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Return info\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m class_index, class_name\n",
      "\u001b[0;31mNameError\u001b[0m: name 'class_descriptions' is not defined"
     ]
    }
   ],
   "source": [
    "class_index, class_name = make_prediction(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9c7573e7-8678-4c61-8dfb-e21ef5566b91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(np.int64(16), 'Vehicles over 3.5 metric tons prohibited')"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_index, class_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d6decb-c63f-421a-b4a5-a9e74ab02e42",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
